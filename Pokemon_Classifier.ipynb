{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "IvKAe6ieeC_9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.models import ResNet101_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "\n",
    "# Set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)\n",
    "\n",
    "print(torch.get_default_device())\n",
    "\n",
    "!nvcc --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdQEkORHG2ge"
   },
   "source": [
    "This code applies three transformations to the input image: resizing it to 128x128 pixels, converting it into a tensor, and normalizing the pixel values according to pre-defined mean and standard deviation values for ResNet models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0vTKHZ4Uevr8"
   },
   "outputs": [],
   "source": [
    "# Define transformations (resize, convert to tensor, and normalize)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),           # Resize to 256x256 first\n",
    "    transforms.CenterCrop(224),       # Crop to 224x224\n",
    "    transforms.ToTensor(),            # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kuhSv4XHKTK"
   },
   "source": [
    "- Loads the images and applies the specified transformations.\n",
    "- random_split divides the dataset into training (80%) and testing (20%) subsets.\n",
    "- DataLoader creates iterators for loading batches of data from the training and test datasets with specified batch sizes, shuffling for training, and parallel data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZvKmRSO7ghf5"
   },
   "outputs": [],
   "source": [
    "generator = torch.Generator(device='cuda')\n",
    "\n",
    "#  load images from /content/images/baseset_001 ,  /content/images/baseset_002,  /content/images/baseset_003 etc...\n",
    "train_data = torchvision.datasets.ImageFolder(root='images', transform=transform)\n",
    "\n",
    "# Split dataset into train and test sets (80% train, 20% test)\n",
    "train_size = int(0.8 * len(train_data))  # 80% for training\n",
    "test_size = len(train_data) - train_size  # The rest for testing\n",
    "\n",
    "# split the dataset\n",
    "train_dataset, test_dataset = random_split(train_data, [train_size, test_size], generator=generator)\n",
    "\n",
    "# Create DataLoader for training and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, generator=generator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2, generator=generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJKbD5_EG0H9"
   },
   "source": [
    "Let's check out the shape of the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMolLLUapM60",
    "outputId": "60277908-28e0-44fa-d79f-31916bd9706e"
   },
   "outputs": [],
   "source": [
    "image, label = train_data[0]\n",
    "image.shape, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1XoOLcvHje8"
   },
   "source": [
    "Let's predefine the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9t463O6pXOm",
    "outputId": "bd4fdd34-fb25-4974-f63a-8bfe280ff81a"
   },
   "outputs": [],
   "source": [
    "# class_names = ['base1-01', 'base1-02', 'base1-03'] etc.\n",
    "class_names = train_data.classes\n",
    "print(f\"{len(class_names)} classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meUhFI_dHpDB"
   },
   "source": [
    "Set device to the current device we are using cude (gpu) or cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6JZZLvkHynf"
   },
   "source": [
    "- A pre-trained ResNet-50 model is loaded with weights from ImageNet.\n",
    "- The final fully connected layer (model.fc) is replaced with a new Linear layer that has as many output units as there are classes in your dataset (len(class_names)).\n",
    "- The model is moved to the device (GPU or CPU).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FzXW6vs-rNSG"
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet101(weights=ResNet101_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(class_names))\n",
    "\n",
    "# compile the model (optimized kernals)\n",
    "compiled_model = torch.compile(model, mode=\"reduce-overhead\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UdgGSZpItrn"
   },
   "source": [
    "**nn.CrossEntropyLoss():** This is a commonly used loss function for multi-class classification problems. It combines softmax activation and negative log-likelihood loss in a single function, making it efficient for classification tasks.\n",
    "\n",
    "**optim.SGD**: This initializes the Stochastic Gradient Descent (SGD) optimizer for training the model. SGD is one of the most common optimization algorithms, which iterates through the training dataset and updates the model's parameters (weights) to minimize the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NVF8NRaQro8X"
   },
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.3, cooldown=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "VxmGyTc6r8i9",
    "outputId": "2a845e2b-49b3-4f01-a720-1d18851f1f08"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = compiled_model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = compiled_model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predicted = outputs.argmax(dim=1) \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Step the scheduler with validation loss\n",
    "    scheduler.step(avg_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "wSgTbMa9s_pr"
   },
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient computation for inference\n",
    "with torch.no_grad():\n",
    "    # Compute total number of correct predictions and total samples\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        # Move data to the same device as the model\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Get model predictions\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Get the predicted class (most confident prediction)\n",
    "        predictions = outputs.argmax(dim=1)\n",
    "        \n",
    "        # Update total samples and correct predictions\n",
    "        total += labels.size(0)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "F7QpGj5hv2T6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Load an image, apply transformations, and prepare it for model inference.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Preprocessed image tensor ready for model input\n",
    "    \"\"\"\n",
    "    # Open the image using PIL\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Apply transformations and prepare for model input\n",
    "    # .unsqueeze(0) adds a batch dimension, as models expect batched input\n",
    "    processed_image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    return processed_image\n",
    "\n",
    "# List of image paths to predict\n",
    "image_paths = [\n",
    "    './test_images/alakazam.jpg', \n",
    "    './test_images/abra.jpg', \n",
    "    './test_images/zapdos.jpg',\n",
    "    './test_images/fossil.webp'\n",
    "]\n",
    "\n",
    "# Preprocess all images\n",
    "images = [load_and_preprocess_image(path) for path in image_paths]\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient computation for inference\n",
    "with torch.no_grad():\n",
    "    for path, image in zip(image_paths, images):\n",
    "        # Run inference\n",
    "        output = model(image)\n",
    "        \n",
    "        # Get the most confident prediction\n",
    "        predicted_index = output.argmax(dim=1).item()\n",
    "        predicted_class = class_names[predicted_index]\n",
    "        \n",
    "        # Print prediction with original image path for context\n",
    "        print(f\"Image: {os.path.basename(path)}\")\n",
    "        print(f\"Predicted class: {predicted_class}\\n\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This saves model weights AND class names:\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'class_names': train_data.classes\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'pokemon_model.pth')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
